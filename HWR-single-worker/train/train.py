import numpy as np
import tensorflow as tf
import os
import time
from datetime import datetime
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist
from sklearn.model_selection import train_test_split

import logging
logging.getLogger("tensorflow").setLevel(logging.ERROR)
tf.autograph.set_verbosity(0)

np.set_printoptions(precision=2)

# âœ… Load bá»™ dá»¯ liá»‡u MNIST
(X_full, y_full), (X_test, y_test) = mnist.load_data()

# âœ… Tiá»n xá»­ lÃ½: flatten + normalize
X_full = X_full.reshape(-1, 28*28).astype("float32") / 255.0
X_test = X_test.reshape(-1, 28*28).astype("float32") / 255.0

# Chuyá»ƒn y vá» shape (n, 1) cho Ä‘á»“ng bá»™
y_full = y_full.reshape(-1, 1)
y_test = y_test.reshape(-1, 1)

# BÆ°á»›c 1: TÃ¡ch ra táº­p Test trÆ°á»›c (20% dá»¯ liá»‡u)
X_temp, X_test, y_temp, y_test = train_test_split(X_full, y_full, test_size=0.2, random_state=42)

# BÆ°á»›c 2: Tá»« pháº§n cÃ²n láº¡i, tÃ¡ch tiáº¿p ra Validation (20% cá»§a 80% cÃ²n láº¡i = 16%)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)

print("âœ… MNIST loaded thÃ nh cÃ´ng!")
print(f"Training samples: {len(X_train)}, Validation: {len(X_val)}, Test: {len(X_test)}")


tf.random.set_seed(1234) # for consistent results

# âœ… Äá»‹nh nghÄ©a model trong `strategy.scope()`

model = tf.keras.Sequential([
    tf.keras.Input(shape=(784,)),     
    tf.keras.layers.Dense(25, activation='relu', name="L1"),
    tf.keras.layers.Dense(15, activation='relu', name="L2"),
    tf.keras.layers.Dense(10, activation='linear', name="L3")
], name="my_model")

model.compile(
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=["accuracy"],  # âœ… thÃªm dÃ²ng nÃ y Ä‘á»ƒ láº¥y accuracy
)

model.summary()

start_time = time.time()

# âœ… Train model vá»›i `verbose=2` Ä‘á»ƒ giáº£m log
history = model.fit(X_train, y_train, epochs=40, verbose=2,validation_data=(X_val, y_val))

end_time = time.time()
elapsed_time = end_time - start_time

start_dt = datetime.fromtimestamp(start_time).strftime("%Y-%m-%d %H:%M:%S")
end_dt = datetime.fromtimestamp(end_time).strftime("%Y-%m-%d %H:%M:%S")

# âœ… Hiá»ƒn thá»‹ káº¿t quáº£ dá»± Ä‘oÃ¡n vá»›i táº­p test Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ khÃ¡ch quan

# Default tÃªn áº£nh
worker_name = "single_worker"

# ÄÆ°á»ng dáº«n áº£nh Ä‘áº§u ra riÃªng biá»‡t
OUTPUT_DIR = "output"
os.makedirs(OUTPUT_DIR, exist_ok=True)
output_path = os.path.join(OUTPUT_DIR, f"predictions_{worker_name}.png")

# âœ… ÄÃ¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p test
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
accuracy_percent = test_accuracy * 100
print(f"ğŸ¯ Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test: {accuracy_percent:.2f}%")

# âœ… Hiá»ƒn thá»‹ káº¿t quáº£ dá»± Ä‘oÃ¡n
m_test = X_test.shape[0]
fig, axes = plt.subplots(8, 8, figsize=(5, 5))
fig.tight_layout(pad=0.13, rect=[0, 0.03, 1, 0.91])

for i, ax in enumerate(axes.flat):
    # Chá»n ngáº«u nhiÃªn áº£nh tá»« táº­p test
    random_index = np.random.randint(m_test)
    
    X_random_reshaped = X_test[random_index].reshape((28, 28)).T
    ax.imshow(X_random_reshaped, cmap='gray')
    
    # Dá»± Ä‘oÃ¡n
    prediction = model.predict(X_test[random_index].reshape(1, 784), verbose=0)
    prediction_p = tf.nn.softmax(prediction).numpy()
    yhat = np.argmax(prediction_p)
    
    # Hiá»ƒn thá»‹ nhÃ£n thá»±c vÃ  nhÃ£n dá»± Ä‘oÃ¡n
    ax.set_title(f"{y_test[random_index, 0]},{yhat}", fontsize=10)
    ax.set_axis_off()

fig.suptitle(f"Label (true), yhat (pred) â€” Accuracy: {accuracy_percent:.2f}%", fontsize=14)
plt.savefig(output_path)

print(f"âœ… Worker lÆ°u áº£nh vÃ o: {output_path}")

print(f"ğŸ§  Worker {worker_name} huáº¥n luyá»‡n tá»« {start_dt} Ä‘áº¿n {end_dt} máº¥t {elapsed_time:.2f} giÃ¢y")

