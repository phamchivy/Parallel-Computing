import numpy as np
import tensorflow as tf
import os
import json
import matplotlib.pyplot as plt
import time
from datetime import datetime
from tensorflow.keras.datasets import mnist
from sklearn.model_selection import train_test_split

import logging
logging.getLogger("tensorflow").setLevel(logging.ERROR)
tf.autograph.set_verbosity(0)

np.set_printoptions(precision=2)

# âœ… Load biáº¿n TF_CONFIG tá»« Docker environment
tf_config = os.getenv("TF_CONFIG")

if tf_config:
    try:
        tf_config = json.loads(tf_config)  # Chuyá»ƒn tá»« chuá»—i JSON sang dict
        print("Using distributed training with TF_CONFIG:", tf_config)
        strategy = tf.distribute.MultiWorkerMirroredStrategy()
    except json.JSONDecodeError:
        print("âš ï¸ Warning: Invalid TF_CONFIG format, switching to single-worker mode")
        strategy = tf.distribute.get_strategy()
else:
    print("Using single-worker training")
    strategy = tf.distribute.get_strategy()

# âœ… Load bá»™ dá»¯ liá»‡u MNIST
(X_full, y_full), (X_test, y_test) = mnist.load_data()

# âœ… Tiá»n xá»­ lÃ½: flatten + normalize
X_full = X_full.reshape(-1, 28*28).astype("float32") / 255.0
X_test = X_test.reshape(-1, 28*28).astype("float32") / 255.0

# Chuyá»ƒn y vá» shape (n, 1) cho Ä‘á»“ng bá»™
y_full = y_full.reshape(-1, 1)
y_test = y_test.reshape(-1, 1)

# BÆ°á»›c 1: TÃ¡ch ra táº­p Test trÆ°á»›c (20% dá»¯ liá»‡u)
X_temp, X_test, y_temp, y_test = train_test_split(X_full, y_full, test_size=0.2, random_state=42)

# BÆ°á»›c 2: Tá»« pháº§n cÃ²n láº¡i, tÃ¡ch tiáº¿p ra Validation (20% cá»§a 80% cÃ²n láº¡i = 16%)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)

print("âœ… MNIST loaded thÃ nh cÃ´ng!")
print(f"Training samples: {len(X_train)}, Validation: {len(X_val)}, Test: {len(X_test)}")

# âœ¨ CHUYá»‚N train data sang tf.data.Dataset
train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))

# âœ¨ Shard theo sá»‘ worker hiá»‡n cÃ³
num_workers = strategy.num_replicas_in_sync
task_id = strategy.cluster_resolver.task_id

train_dataset = train_dataset.shard(num_shards=num_workers, index=task_id)

print(f"ğŸ”§ Worker {task_id}/{num_workers} â€” Dataset size after shard: {len(list(train_dataset.as_numpy_iterator()))}")


# âœ¨ Shuffle, batch vÃ  prefetch
BATCH_SIZE = 64
train_dataset = train_dataset.shuffle(10000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)


tf.random.set_seed(1234) # for consistent results

# âœ… Äá»‹nh nghÄ©a model trong `strategy.scope()`
with strategy.scope():
    model = tf.keras.Sequential([
        tf.keras.Input(shape=(784,)),     
        tf.keras.layers.Dense(25, activation='relu', name="L1"),
        tf.keras.layers.Dense(15, activation='relu', name="L2"),
        tf.keras.layers.Dense(10, activation='linear', name="L3")
    ], name="my_model")

    model.compile(
        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
        metrics=["accuracy"],  # âœ… thÃªm dÃ²ng nÃ y Ä‘á»ƒ láº¥y accuracy
    )

model.summary()

start_time = time.time()

# âœ… Train model vá»›i `verbose=2` Ä‘á»ƒ giáº£m log
history = model.fit(train_dataset, epochs=40, validation_data=(X_val, y_val), verbose=2)

end_time = time.time()
elapsed_time = end_time - start_time

start_dt = datetime.fromtimestamp(start_time).strftime("%Y-%m-%d %H:%M:%S")
end_dt = datetime.fromtimestamp(end_time).strftime("%Y-%m-%d %H:%M:%S")

# âœ… Hiá»ƒn thá»‹ káº¿t quáº£ dá»± Ä‘oÃ¡n vá»›i táº­p test Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ khÃ¡ch quan

# Default tÃªn áº£nh
worker_name = "worker_unknown"

if tf_config:
    try:
        task = tf_config.get("task", {})
        worker_type = task.get("type", "worker")
        worker_index = task.get("index", 0)
        worker_name = f"{worker_type}_{worker_index}"
    except:
        pass

# ÄÆ°á»ng dáº«n áº£nh Ä‘áº§u ra riÃªng biá»‡t
OUTPUT_DIR = "output"
os.makedirs(OUTPUT_DIR, exist_ok=True)
output_path = os.path.join(OUTPUT_DIR, f"predictions_{worker_name}.png")

# âœ… ÄÃ¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p test
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
accuracy_percent = test_accuracy * 100
print(f"ğŸ¯ Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test: {accuracy_percent:.2f}%")

# âœ… Hiá»ƒn thá»‹ káº¿t quáº£ dá»± Ä‘oÃ¡n
m_test = X_test.shape[0]
fig, axes = plt.subplots(8, 8, figsize=(5, 5))
fig.tight_layout(pad=0.13, rect=[0, 0.03, 1, 0.91])

for i, ax in enumerate(axes.flat):
    # Chá»n ngáº«u nhiÃªn áº£nh tá»« táº­p test
    random_index = np.random.randint(m_test)
    
    X_random_reshaped = X_test[random_index].reshape((28, 28)).T
    ax.imshow(X_random_reshaped, cmap='gray')
    
    # Dá»± Ä‘oÃ¡n
    prediction = model.predict(X_test[random_index].reshape(1, 784), verbose=0)
    prediction_p = tf.nn.softmax(prediction).numpy()
    yhat = np.argmax(prediction_p)
    
    # Hiá»ƒn thá»‹ nhÃ£n thá»±c vÃ  nhÃ£n dá»± Ä‘oÃ¡n
    ax.set_title(f"{y_test[random_index, 0]},{yhat}", fontsize=10)
    ax.set_axis_off()

fig.suptitle(f"Label (true), yhat (pred) â€” Accuracy: {accuracy_percent:.2f}%", fontsize=14)
plt.savefig(output_path)

print(f"âœ… Worker lÆ°u áº£nh vÃ o: {output_path}%")

print(f"ğŸ§  Worker {worker_name} huáº¥n luyá»‡n tá»« {start_dt} Ä‘áº¿n {end_dt} máº¥t {elapsed_time:.2f} giÃ¢y")


